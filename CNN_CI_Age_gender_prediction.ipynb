{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "name": "CNN_CI_Age_gender_prediction.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shailendra995/CI_project/blob/main/CNN_CI_Age_gender_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECgvs35mtAuT"
      },
      "source": [
        "#install Laggle\n",
        "!pip install -q kaggle "
      ],
      "id": "ECgvs35mtAuT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohH8zioVuJZ3"
      },
      "source": [
        "from google.colab import files \n",
        "files.upload()"
      ],
      "id": "ohH8zioVuJZ3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3y3PoEozSUI"
      },
      "source": [
        "!nvcc --version\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed')>=0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "    print(gpu_info)"
      ],
      "id": "_3y3PoEozSUI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kj9QG2qnxZjX"
      },
      "source": [
        "#create a kaggle folder\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/kaggle.json\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "id": "kj9QG2qnxZjX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ER4nJ_Joy2xZ"
      },
      "source": [
        "!kaggle datasets list"
      ],
      "id": "ER4nJ_Joy2xZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nP3YHgVNSXEL"
      },
      "source": [
        "!kaggle datasets download -d ttungl/adience-benchmark-gender-and-age-classification "
      ],
      "id": "nP3YHgVNSXEL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4y0RYnZxVBPg"
      },
      "source": [
        "!unzip adience-benchmark-gender-and-age-classification.zip"
      ],
      "id": "4y0RYnZxVBPg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQdQaL_NqrOE"
      },
      "source": [
        "import os\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ],
      "id": "gQdQaL_NqrOE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6pRJGGCWIS6"
      },
      "source": [
        "data_parent = 'AdienceBenchmarkGenderAndAgeClassification'\n",
        "print(os.listdir(data_parent))"
      ],
      "id": "T6pRJGGCWIS6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObinHTe6V_Kf"
      },
      "source": [
        "\n",
        "fold_0 = pd.read_csv(os.path.join(data_parent, 'fold_0_data.txt'), sep='\\t')\n",
        "fold_1 = pd.read_csv(os.path.join(data_parent, 'fold_1_data.txt'),sep='\\t')\n",
        "fold_2 = pd.read_csv(os.path.join(data_parent, 'fold_2_data.txt'),sep='\\t')\n",
        "fold_3 = pd.read_csv(os.path.join(data_parent, 'fold_3_data.txt'),sep='\\t')\n",
        "fold_4 = pd.read_csv(os.path.join(data_parent, 'fold_4_data.txt'),sep='\\t')\n",
        "total_data = pd.concat([fold_0, fold_1, fold_2, fold_3, fold_4], ignore_index=True)\n",
        "total_data.head()"
      ],
      "id": "ObinHTe6V_Kf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6f2714f9"
      },
      "source": [
        "print('[+] length of the file:', len(total_data))\n",
        "print('[+] unique values of Age:')\n",
        "print(total_data.age.unique())\n",
        "print('===================================================')\n",
        "print('[+] Number of None Values in Age:')\n",
        "print((total_data.age == 'None').sum())\n",
        "print('[+] unique values of Gender:')\n",
        "print(total_data.gender.unique())\n",
        "print('===================================================')\n",
        "print('[+] Number of nan values in Gender:')\n",
        "print(total_data.gender.isna().sum())"
      ],
      "id": "6f2714f9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "986314f8"
      },
      "source": [
        "# Gender chart"
      ],
      "id": "986314f8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0d5ddf4",
        "scrolled": true
      },
      "source": [
        "total_data.groupby('gender')['gender'].count().plot.pie(figsize=(8, 4))"
      ],
      "id": "d0d5ddf4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43bb9d89"
      },
      "source": [
        "#bar chart\n",
        "gender = ['f','m','u']\n",
        "plt.bar(gender,total_data.gender.value_counts(), align='center', alpha=0.5)\n",
        "plt.show()"
      ],
      "id": "43bb9d89",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "db742da9"
      },
      "source": [
        "#total_data.groupby('age')['age'].count().plot.pie(figsize=(10, 5))"
      ],
      "id": "db742da9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5270688"
      },
      "source": [
        "sample_num = 200\n",
        "im_name = total_data.iloc[sample_num].original_image\n",
        "im_path = os.path.join(data_parent, 'faces',str(total_data.iloc[sample_num].user_id), 'coarse_tilt_aligned_face.' + str(total_data.iloc[sample_num].face_id) + '.' + im_name)\n",
        "print('[+] Image path:', im_path)\n",
        "image = cv2.imread(im_path)\n",
        "print('[+] Image shape:', image.shape)\n",
        "print('[!] Age:', total_data.iloc[sample_num].age, 'Gender:', total_data.iloc[sample_num].gender)\n",
        "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))"
      ],
      "id": "a5270688",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5a797e7"
      },
      "source": [
        "images = []\n",
        "for _ in range(16):\n",
        "    sample_num = random.randint(0, len(total_data))\n",
        "    im_name = total_data.iloc[sample_num].original_image\n",
        "    im_path = os.path.join(data_parent, 'faces',str(total_data.iloc[sample_num].user_id), 'coarse_tilt_aligned_face.' + str(total_data.iloc[sample_num].face_id) + '.' + im_name)\n",
        "    image = cv2.imread(im_path)\n",
        "    age = total_data.iloc[sample_num].age\n",
        "    gender = total_data.iloc[sample_num].gender\n",
        "    n_col = 4\n",
        "    n_rows = 4\n",
        "    images.append((image, age, gender))\n",
        "    \n",
        "fig, axs = plt.subplots(ncols=n_col, nrows=n_rows, figsize=(15,15))\n",
        "count = 0\n",
        "for i in range(n_rows):\n",
        "      for j in range(n_col):\n",
        "        axs[i][j].imshow(cv2.cvtColor(images[count][0], cv2.COLOR_BGR2RGB))\n",
        "        axs[i][j].set_title(f'Age: {images[count][1]}, Gender: {images[count][2]}')\n",
        "        count+=1\n",
        "plt.show()"
      ],
      "id": "e5a797e7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "107d48d9"
      },
      "source": [
        "age_mapping = [('(0, 2)', '0-2'), ('2', '0-2'), ('3', '0-2'), ('(4, 6)', '4-6'), ('(8, 12)', '8-13'), ('13', '8-13'), ('22', '15-20'), ('(8, 23)','15-20'), ('23', '25-32'), ('(15, 20)', '15-20'), ('(25, 32)', '25-32'), ('(27, 32)', '25-32'), ('32', '25-32'), ('34', '25-32'), ('29', '25-32'), ('(38, 42)', '38-43'), ('35', '38-43'), ('36', '38-43'), ('42', '48-53'), ('45', '38-43'), ('(38, 43)', '38-43'), ('(38, 42)', '38-43'), ('(38, 48)', '48-53'), ('46', '48-53'), ('(48, 53)', '48-53'), ('55', '48-53'), ('56', '48-53'), ('(60, 100)', '60+'), ('57', '60+'), ('58', '60+')]\n",
        "age_mapping_dict = {each[0]: each[1] for each in age_mapping}\n",
        "\n",
        "drop_labels = []\n",
        "for idx, each in enumerate(total_data.age):\n",
        "    if each == 'None':\n",
        "        drop_labels.append(idx)\n",
        "    else:\n",
        "        total_data.age.loc[idx] = age_mapping_dict[each]\n",
        "total_data = total_data.drop(labels=drop_labels, axis=0) #droped None values\n",
        "total_data.age.value_counts(dropna=False)"
      ],
      "id": "107d48d9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3e4f3ac"
      },
      "source": [
        "total_data = total_data.dropna()\n",
        "total_data['full_path'] = total_data.apply(lambda x: os.path.join(data_parent, 'faces', str(x.user_id), 'coarse_tilt_aligned_face.' + str(x.face_id) + '.' + x.original_image), axis=1)\n",
        "total_data.age.unique(), len(total_data.age.unique()), total_data.gender.unique()"
      ],
      "id": "a3e4f3ac",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96229c94"
      },
      "source": [
        "# Change age and gender mapping"
      ],
      "id": "96229c94"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eabb973"
      },
      "source": [
        "\n",
        "gender_map = {'f':0, \n",
        "             'm':1,\n",
        "             'u':2}\n",
        "age_map = {\n",
        "    '0-2'  :0,\n",
        "    '4-6'  :1,\n",
        "    '8-13' :2,\n",
        "    '15-20':3,\n",
        "    '25-32':4,\n",
        "    '38-43':5,\n",
        "    '48-53':6,\n",
        "    '60+'  :7\n",
        "}\n",
        "total_data.gender = total_data.gender.replace(gender_map)\n",
        "total_data.age=total_data.age.replace(age_map)"
      ],
      "id": "7eabb973",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "717c4e9e"
      },
      "source": [
        "gender_labels = total_data.gender.values.tolist()\n",
        "age_labels= total_data.age.values.tolist()\n",
        "train_paths = total_data.full_path.values.tolist()\n",
        "len(gender_labels), gender_labels[0],len(age_labels),age_labels[0], train_paths[0]"
      ],
      "id": "717c4e9e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5650163e"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "id": "5650163e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5211bca"
      },
      "source": [
        "shuffle_list = list(zip(train_paths, gender_labels,age_labels))\n",
        "shuffle_list = random.sample(shuffle_list, len(train_paths))\n",
        "train_paths, gender_labels,age_labels = zip(*shuffle_list)\n",
        "age_labels = np.array(list(age_labels)).reshape((-1, 1))\n",
        "enc= OneHotEncoder()\n",
        "age_labels = enc.fit_transform(age_labels).toarray() "
      ],
      "id": "b5211bca",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bacc231"
      },
      "source": [
        "train_split = 0.8\n",
        "train_sample = int(train_split * len(total_data))\n",
        "\n",
        "train_data = train_paths[:train_sample]\n",
        "validation_data = train_paths[train_sample:]\n",
        "\n",
        "train_labels_gender = gender_labels[:train_sample]\n",
        "validation_labels_gender = gender_labels[train_sample:]\n",
        "\n",
        "train_labels_age=age_labels[:train_sample]\n",
        "validation_labels_age=age_labels[train_sample:]\n",
        "print(\"train data count:\")\n",
        "len(train_data), len(train_labels_gender), len(train_labels_age)\n",
        "# print(\"validation data count:\")\n",
        "# len(validation_data), len(validation_labels)"
      ],
      "id": "0bacc231",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9a560854"
      },
      "source": [
        "train_split = 0.8\n",
        "X = int(train_split * len(total_data))\n",
        "\n",
        "X_train = train_paths[:X]\n",
        "X_test = train_paths[train_sample:]\n",
        "\n",
        "train_labels_gender = gender_labels[:X]\n",
        "validation_labels_gender = gender_labels[X:]\n",
        "\n",
        "y_train=age_labels[:X]\n",
        "y_test=age_labels[X:]\n",
        "print(\"train data count:\")\n",
        "len(train_data), len(train_labels_gender), len(train_labels_age)\n",
        "# print(\"validation data count:\")\n",
        "# len(validation_data), len(validation_labels)"
      ],
      "id": "9a560854",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1151761"
      },
      "source": [
        "import tensorflow as tf\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import multiprocessing"
      ],
      "id": "a1151761",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "be64a7f6"
      },
      "source": [
        "# train_dataset = tf.data.Dataset.from_tensor_slices((list(train_data), list(train_labels_gender),list(train_labels_age)))\n",
        "# validation_dataset = tf.data.Dataset.from_tensor_slices((list(validation_data), list(validation_labels_gender),list(validation_labels_age)))\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((list(train_data), list(train_labels_age)))\n",
        "validation_dataset = tf.data.Dataset.from_tensor_slices((list(validation_data),list(validation_labels_age)))"
      ],
      "id": "be64a7f6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eb8c66d8"
      },
      "source": [
        "# for path, target1,target2 in train_dataset.take(1):\n",
        "#     print(path, target1,target2)\n",
        "for path, target1 in train_dataset.take(1):\n",
        "    print(path, target1)"
      ],
      "id": "eb8c66d8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4687b88"
      },
      "source": [
        "# def preprocess_func(path, label_gender,label_age):\n",
        "#     image = tf.io.read_file(path)\n",
        "#     image = tf.image.decode_jpeg(image, channels=3)\n",
        "#     image = tf.image.resize(image, [128, 128]) / 255.0\n",
        "        \n",
        "#     return image, label_gender, label_age\n",
        "\n",
        "def preprocess_func(path, label_age):\n",
        "    image = tf.io.read_file(path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.resize(image, [128, 128]) / 255.0\n",
        "        \n",
        "    return image, label_age"
      ],
      "id": "e4687b88",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f55a29da"
      },
      "source": [
        "import multiprocessing\n",
        "\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, Dropout, BatchNormalization, Flatten, Dense, MaxPooling2D\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import mean_absolute_error, confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error"
      ],
      "id": "f55a29da",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rj5mcsNnOl0x"
      },
      "source": [
        "**Gender Classification Model**"
      ],
      "id": "Rj5mcsNnOl0x"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64ad6ee6"
      },
      "source": [
        "# Gender Classification with results"
      ],
      "id": "64ad6ee6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fb11476"
      },
      "source": [
        "train_dataset2 = tf.data.Dataset.from_tensor_slices((list(train_data), list(train_labels_gender)))\n",
        "validation_dataset2 = tf.data.Dataset.from_tensor_slices((list(validation_data),list(validation_labels_gender)))"
      ],
      "id": "2fb11476",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6dfee18"
      },
      "source": [
        "for path, target1 in train_dataset2.take(1):\n",
        "    print(path, target1)"
      ],
      "id": "a6dfee18",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7870a7f"
      },
      "source": [
        "train_batches2 = train_dataset2.shuffle(100).map(preprocess_func, num_parallel_calls=multiprocessing.cpu_count()).cache().batch(16).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "validation_batches2 = validation_dataset2.shuffle(100).map(preprocess_func, num_parallel_calls=multiprocessing.cpu_count()).cache().batch(16).prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "id": "b7870a7f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "720ee7f1"
      },
      "source": [
        "\n",
        "for image, target1 in train_batches2.take(1):\n",
        "    print(image.shape, target1.shape)\n",
        "    image = tf.squeeze(image[0])\n",
        "    print(target1[0])\n",
        "\n",
        "    plt.imshow(image)\n",
        "    plt.show()\n",
        "    break"
      ],
      "id": "720ee7f1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8f040fad"
      },
      "source": [
        "def preprocess_func(path, label_gender):\n",
        "    image = tf.io.read_file(path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.resize(image, [128, 128]) / 255.0\n",
        "        \n",
        "    return image, label_gender"
      ],
      "id": "8f040fad",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25ce3a39"
      },
      "source": [
        "for image, target1 in train_batches2.take(20):\n",
        "    print(image.shape, target1.shape)\n",
        "    image = tf.squeeze(image[1])\n",
        "    print(target1[1])\n",
        "\n",
        "    plt.imshow(image)\n",
        "    plt.show()\n",
        "    break"
      ],
      "id": "25ce3a39",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0cfa7df"
      },
      "source": [
        "gender_model = Sequential()\n",
        "\n",
        "gender_model.add(Conv2D(64, kernel_size=(3,3), input_shape=(128, 128, 3), activation='elu'))\n",
        "gender_model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "gender_model.add(BatchNormalization())\n",
        "\n",
        "gender_model.add(Conv2D(128, kernel_size=(3,3), activation='elu'))\n",
        "gender_model.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\n",
        "gender_model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "gender_model.add(Dropout(0.4))\n",
        "gender_model.add(BatchNormalization())\n",
        "\n",
        "gender_model.add(Conv2D(256, kernel_size=(3,3), activation='elu'))\n",
        "gender_model.add(Conv2D(256, kernel_size=(3,3), activation='elu'))\n",
        "gender_model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "gender_model.add(Dropout(0.5))\n",
        "gender_model.add(BatchNormalization())\n",
        "\n",
        "gender_model.add(Flatten())\n",
        "\n",
        "gender_model.add(Dense(64, activation='elu'))\n",
        "gender_model.add(Dropout(0.4))\n",
        "\n",
        "gender_model.add(Dense(1, activation='sigmoid')) #For binary classification activation function is sigmoid \n",
        "\n",
        "gender_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) #...and loss function is binary_crossentropy\n",
        "\n",
        "gender_model.summary()\n",
        "\n"
      ],
      "id": "d0cfa7df",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c77014a6"
      },
      "source": [
        "tf.keras.utils.plot_model(gender_model, show_shapes=True)"
      ],
      "id": "c77014a6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUROYkbQfhF_"
      },
      "source": [
        "#tf.keras.utils.plot_model(gender_model, to_file='model.png')"
      ],
      "id": "lUROYkbQfhF_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5dcf6a0"
      },
      "source": [
        " history = gender_model.fit(train_batches2, epochs=50, validation_data = validation_batches2)"
      ],
      "id": "f5dcf6a0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9428c1e1"
      },
      "source": [
        "plt.plot(history.history['accuracy'], label='accuracy',color= 'red')\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy',color =\"cyan\")\n",
        "plt.xlabel('Gender Detection: 50 epoche elu', fontsize =18)\n",
        "plt.ylabel('Accuracy',fontsize=18)\n",
        "plt.ylim([0.2, 1])\n",
        "plt.legend(loc='upper right', fontsize= 18)"
      ],
      "id": "9428c1e1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90b689ae"
      },
      "source": [
        "image_path = validation_data[7]\n",
        "image = cv2.imread(image_path)\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "image = cv2.resize(image, (128, 128)) / 255.0\n",
        "plt.imshow(image)\n",
        "plt.show()"
      ],
      "id": "90b689ae",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8fc58e8"
      },
      "source": [
        "image = np.expand_dims(image, 0)\n",
        "prediction = gender_model.predict(image)"
      ],
      "id": "a8fc58e8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55779c0b"
      },
      "source": [
        "index = np.argmax(prediction)\n",
        "decoding = {0:'f', 1:'m', 2:'u'}\n",
        "\n",
        "print('[] prediction is :', decoding[index]) "
      ],
      "id": "55779c0b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FF9vcoxbP5W8"
      },
      "source": [
        "**Age Classification**\n"
      ],
      "id": "FF9vcoxbP5W8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHYLB2xpP3Bz"
      },
      "source": [
        ""
      ],
      "id": "IHYLB2xpP3Bz"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bf55FRn4CskG"
      },
      "source": [
        ""
      ],
      "id": "bf55FRn4CskG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q25IWqxiCtGg"
      },
      "source": [
        "train_batches = train_dataset.shuffle(100).map(preprocess_func, num_parallel_calls=multiprocessing.cpu_count()).cache().batch(16).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "validation_batches = validation_dataset.shuffle(100).map(preprocess_func, num_parallel_calls=multiprocessing.cpu_count()).cache().batch(16).prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "id": "Q25IWqxiCtGg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FLbV7F5hsWl"
      },
      "source": [
        "for image, target1 in train_batches.take(1):\n",
        "    print(image.shape, target1.shape)\n",
        "    image = tf.squeeze(image[0])\n",
        "    print(target1[0])\n",
        "\n",
        "    plt.imshow(image)\n",
        "    plt.show()\n",
        "    break"
      ],
      "id": "-FLbV7F5hsWl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bf7b4562"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(8, 3, padding='same', strides=2, activation='elu', input_shape=(128, 128, 3)),\n",
        "#     tf.keras.layers.MaxPooling2D(),\n",
        "#     tf.keras.layers.Dropout(0.3),\n",
        "    \n",
        "    tf.keras.layers.Conv2D(16, 3, padding='same', activation='elu'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "#     tf.keras.layers.Dropout(0.35),\n",
        "    \n",
        "    tf.keras.layers.Conv2D(32, 3, padding='same', activation='elu'),\n",
        "#     tf.keras.layers.MaxPooling2D(),\n",
        "#     tf.keras.layers.Dropout(0.45),\n",
        "    \n",
        "    tf.keras.layers.Conv2D(64, 3, padding='same', activation='elu'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "     tf.keras.layers.Dropout(0.5),\n",
        "    \n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(8, activation = 'softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss= tf.losses.CategoricalCrossentropy(), metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "id": "bf7b4562",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "206b2356"
      },
      "source": [
        "tf.keras.utils.plot_model(model, show_shapes=True)"
      ],
      "id": "206b2356",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1c6be59"
      },
      "source": [
        "# Age classification (training with results)"
      ],
      "id": "b1c6be59"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ed3e1e4c"
      },
      "source": [
        " history = model.fit(train_batches, epochs=50, validation_data = validation_batches)"
      ],
      "id": "ed3e1e4c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61c201d3"
      },
      "source": [
        "plt.plot(history.history['accuracy'], label='accuracy', color= 'blue')\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy', color ='red')\n",
        "plt.xlabel('Age Detection: 50 epoche ELU Act Function', fontsize =15)\n",
        "plt.ylabel('Accuracy', fontsize =18)\n",
        "plt.ylim([0.5, 1])\n",
        "plt.legend(loc='upper left',fontsize =16)\n",
        "#plt.savefig('/home/shailendra/Desktop/Ci_fig/elu_act_10epoch.pdf', dpi=200) "
      ],
      "id": "61c201d3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dba6d58"
      },
      "source": [
        "image_path = validation_data[7]\n",
        "image = cv2.imread(image_path)\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "image = cv2.resize(image, (128, 128)) / 255.0\n",
        "plt.imshow(image)\n",
        "plt.show()"
      ],
      "id": "0dba6d58",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72ecde14"
      },
      "source": [
        "image = np.expand_dims(image, 0)\n",
        "prediction = model.predict(image)"
      ],
      "id": "72ecde14",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3d718d1e"
      },
      "source": [
        "index = np.argmax(prediction)\n",
        "decoding = {0:'0-2', 1:'4-6', 2:'8-13',3:'15-20',4:'25-32',5:'38-43',6:'48-53',7:'60+'}\n",
        "\n",
        "print('[+] prediction is :', decoding[index]) \n",
        "# print(validation_data[7].age_labels)"
      ],
      "id": "3d718d1e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77a6dd32"
      },
      "source": [
        ""
      ],
      "id": "77a6dd32",
      "execution_count": null,
      "outputs": []
    }
  ]
}